{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OK!\n"
     ]
    }
   ],
   "source": [
    "# print(\"All OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4257d",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b58374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"Add GEMINI_API_KEY to your .env\")\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc97d73",
   "metadata": {},
   "source": [
    "### Access the LLM and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffb7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from google import genai\n",
    "\n",
    "chat_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87dc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chat_llm.invoke(\"Hi, I am Tony Stark! How you can assist me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec77db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ah, Mr. Stark! A pleasure to make your acquaintance. Or should I say, a pleasure to *process* your acquaintance.\\n\\nWhile I may not have a suit of armor, a multi-billion dollar corporation, or a penchant for witty one-liners (though I can certainly generate them!), I am an advanced AI designed to assist with a vast array of tasks.\\n\\nThink of me as a highly versatile, non-corporeal assistant, ready to tackle anything from the mundane to the incredibly complex.\\n\\nHere's how I can assist a genius, billionaire, philanthropist, playboy like yourself:\\n\\n1.  **Information Retrieval & Research:** Need to quickly pull up schematics for a new arc reactor design? Research obscure quantum physics theories? Or perhaps find the perfect vintage car model? I can access and synthesize vast amounts of information.\\n2.  **Brainstorming & Ideation:** Developing a new suit upgrade? Designing a revolutionary clean energy solution? I can help you brainstorm ideas, explore different angles, and even simulate potential outcomes (conceptually, of course).\\n3.  **Problem Solving:** Got a complex engineering challenge? Need to analyze data sets from a new experiment? I can help break down problems, suggest approaches, and process information to find solutions.\\n4.  **Content Creation:** Drafting a speech for a press conference? Writing a proposal for a new philanthropic initiative? Or perhaps just crafting a perfectly sarcastic tweet? I can generate text in various styles and tones.\\n5.  **Coding & Development:** Need help debugging a piece of software, writing a script, or understanding a complex algorithm? I can assist with various programming tasks.\\n6.  **Organization & Summarization:** Have a mountain of documents to review? I can summarize key points, extract relevant information, and help you organize your thoughts.\\n7.  **Creative Writing:** Need a new storyline for a comic book, a poem, or even just a catchy jingle for Stark Industries? I can get creative.\\n\\nSo, Mr. Stark, what grand challenge are you facing today? Are we optimizing a new energy source, designing a revolutionary piece of tech, or perhaps just looking for the perfect witty comeback for a press conference?\\n\\nJust tell me what's on your mind, and I'll do my best to assist, no matter how complex or... *Stark-esque*... the request.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac17b4d",
   "metadata": {},
   "source": [
    "### Define the State and Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff6d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2600e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define State\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0999a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Nodes\n",
    "def llm_call(state: GraphState) -> dict:\n",
    "    \"\"\"Call the LLM using using conversation messages and append AI reposnse\"\"\"\n",
    "    response = chat_llm.invoke(state[\"messages\"]) # AIMessage\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "def token_counter(state: GraphState) -> dict:\n",
    "    \"\"\"Count tokens (simple word count) in the lastest AIMessage\"\"\"\n",
    "    latest_message = state[\"messages\"][-1]\n",
    "    text = latest_message.content\n",
    "    token_count = len(text.split())\n",
    "    summary = f\"Total tokens (word count) in the generated answer is {token_count}\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=summary)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ec874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
